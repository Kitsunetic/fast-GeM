{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7be4cc25-d4ce-4794-bc8f-b15c54a61f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88968464-264b-45f1-af23-486adeb8e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Union\n",
    "\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "import triton\n",
    "import triton.language as tl\n",
    "from kitsu.utils.utils import cummul\n",
    "from torch import Tensor, nn\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from fast_gem.functional import triton_utils as tu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c533228-014b-4c51-8824-5cebe5167c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.cuda.set_device(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "410e3405-f6f1-4260-91a8-4fdd3795f553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gem_torch_3d(x: Tensor, p: Union[float, Tensor] = 3.0, eps=1e-6, keepdim=True):\n",
    "    assert x.ndim == 5, f\"Unknown `x` shape: {x.shape}\"\n",
    "    x = x.clamp_min(eps).pow_(p).mean((2, 3, 4), keepdim=keepdim).pow_(1.0 / p)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d22e9ae-7e80-4626-9745-b0f4afd77be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    configs=[\n",
    "        # triton.Config({\"BLK_L\": 256, \"BLK_M\": 32, \"BLK_N\": 32}),\n",
    "        # triton.Config({\"BLK_L\": 128, \"BLK_M\": 64, \"BLK_N\": 32}),\n",
    "        # triton.Config({\"BLK_L\": 128, \"BLK_M\": 32, \"BLK_N\": 64}),\n",
    "        # triton.Config({\"BLK_L\": 64, \"BLK_M\": 128, \"BLK_N\": 32}),\n",
    "        # triton.Config({\"BLK_L\": 64, \"BLK_M\": 64, \"BLK_N\": 64}),\n",
    "        # triton.Config({\"BLK_L\": 64, \"BLK_M\": 32, \"BLK_N\": 128}),\n",
    "        # triton.Config({\"BLK_L\": 32, \"BLK_M\": 256, \"BLK_N\": 32}),\n",
    "        # triton.Config({\"BLK_L\": 32, \"BLK_M\": 128, \"BLK_N\": 64}),\n",
    "        # triton.Config({\"BLK_L\": 32, \"BLK_M\": 64, \"BLK_N\": 128}),\n",
    "        triton.Config({\"BLK_L\": 32, \"BLK_M\": 32, \"BLK_N\": 256}),\n",
    "    ],\n",
    "    key=[\"str_x_L\", \"str_x_M\", \"str_x_N\"],\n",
    ")\n",
    "@triton.jit\n",
    "def gem_forward_3d_kernel(\n",
    "    x_ptr,\n",
    "    y_ptr,\n",
    "    p,\n",
    "    eps,\n",
    "    str_x_B,\n",
    "    str_x_C,\n",
    "    str_x_L,\n",
    "    str_x_M,\n",
    "    str_x_N,\n",
    "    str_y_B,\n",
    "    str_y_C,\n",
    "    L,\n",
    "    M,\n",
    "    N,\n",
    "    IS_P_TENSOR: tl.constexpr,\n",
    "    BLK_L: tl.constexpr,\n",
    "    BLK_M: tl.constexpr,\n",
    "    BLK_N: tl.constexpr,\n",
    "):\n",
    "    pid_b = tl.program_id(0)\n",
    "    pid_c = tl.program_id(1)\n",
    "    offs_l = tl.arange(0, BLK_L)  # l\n",
    "    offs_m = tl.arange(0, BLK_M)  # m\n",
    "    offs_n = tl.arange(0, BLK_N)  # m\n",
    "    x_ptrs = (\n",
    "        x_ptr\n",
    "        + pid_b * str_x_B\n",
    "        + pid_c * str_x_C\n",
    "        + offs_l[:, None, None] * str_x_L\n",
    "        + offs_m[None, :, None] * str_x_M\n",
    "        + offs_n[None, None, :] * str_x_N\n",
    "    )\n",
    "\n",
    "    if IS_P_TENSOR:\n",
    "        p = tl.load(p)\n",
    "\n",
    "    y = 0.0\n",
    "    for idx_l in range(tl.cdiv(L, BLK_L)):\n",
    "        mask_l = offs_l[:, None, None] < L - idx_l * BLK_L\n",
    "        for idx_m in range(tl.cdiv(M, BLK_M)):\n",
    "            mask_m = offs_m[None, :, None] < M - idx_m * BLK_M\n",
    "            for idx_n in range(tl.cdiv(N, BLK_N)):\n",
    "                mask = mask_l & mask_m & (offs_n[None, None, :] < N - idx_n * BLK_N)\n",
    "\n",
    "                x = tl.load(x_ptrs, mask=mask, other=0.0)  # l m\n",
    "\n",
    "                # calculate adaptive average pooling\n",
    "                x = tl.where((x < eps) & mask, eps, x)\n",
    "                x = tu.pow(x, p)  # l\n",
    "                y += tl.sum(x)  # 1\n",
    "\n",
    "                x_ptrs += BLK_N * str_x_N\n",
    "            x_ptrs += BLK_M * str_x_M\n",
    "        x_ptrs += BLK_L * str_x_L\n",
    "\n",
    "    y /= L * M * N\n",
    "    y = tu.pow(y, 1 / p)\n",
    "\n",
    "    y_ptrs = y_ptr + pid_b * str_y_B + pid_c * str_y_C\n",
    "    tl.store(y_ptrs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1ff0ea9-8cec-4800-857a-617296cb3b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    configs=[\n",
    "        # triton.Config({\"BLK_L\": 256, \"BLK_M\": 32, \"BLK_N\": 32}),\n",
    "        # triton.Config({\"BLK_L\": 128, \"BLK_M\": 64, \"BLK_N\": 32}),\n",
    "        # triton.Config({\"BLK_L\": 128, \"BLK_M\": 32, \"BLK_N\": 64}),\n",
    "        # triton.Config({\"BLK_L\": 64, \"BLK_M\": 128, \"BLK_N\": 32}),\n",
    "        # triton.Config({\"BLK_L\": 64, \"BLK_M\": 64, \"BLK_N\": 64}),\n",
    "        # triton.Config({\"BLK_L\": 64, \"BLK_M\": 32, \"BLK_N\": 128}),\n",
    "        # triton.Config({\"BLK_L\": 32, \"BLK_M\": 256, \"BLK_N\": 32}),\n",
    "        # triton.Config({\"BLK_L\": 32, \"BLK_M\": 128, \"BLK_N\": 64}),\n",
    "        # triton.Config({\"BLK_L\": 32, \"BLK_M\": 64, \"BLK_N\": 128}),\n",
    "        triton.Config({\"BLK_L\": 32, \"BLK_M\": 32, \"BLK_N\": 256}),\n",
    "    ],\n",
    "    key=[\"str_x_L\", \"str_x_M\", \"str_x_N\"],\n",
    "    reset_to_zero=[\"dp_ptr\"],\n",
    ")\n",
    "@triton.jit\n",
    "def gem_backward_3d_kernel(\n",
    "    x_ptr,\n",
    "    y_ptr,\n",
    "    p,\n",
    "    dx_ptr,\n",
    "    dy_ptr,\n",
    "    dp_ptr,\n",
    "    eps,\n",
    "    str_x_B,\n",
    "    str_x_C,\n",
    "    str_x_L,\n",
    "    str_x_M,\n",
    "    str_x_N,\n",
    "    str_y_B,\n",
    "    str_y_C,\n",
    "    L,\n",
    "    M,\n",
    "    N,\n",
    "    IS_P_TENSOR: tl.constexpr,\n",
    "    BLK_L: tl.constexpr,\n",
    "    BLK_M: tl.constexpr,\n",
    "    BLK_N: tl.constexpr,\n",
    "):\n",
    "    pid_b = tl.program_id(0)\n",
    "    pid_c = tl.program_id(1)\n",
    "    offs_l = tl.arange(0, BLK_L)  # l\n",
    "    offs_m = tl.arange(0, BLK_M)  # m\n",
    "    offs_n = tl.arange(0, BLK_N)  # m\n",
    "\n",
    "    offs_x = (\n",
    "        pid_b * str_x_B\n",
    "        + pid_c * str_x_C\n",
    "        + offs_l[:, None, None] * str_x_L\n",
    "        + offs_m[None, :, None] * str_x_M\n",
    "        + offs_n[None, None, :] * str_x_N\n",
    "    )\n",
    "    x_ptrs = x_ptr + offs_x\n",
    "    dx_ptrs = dx_ptr + offs_x\n",
    "    y_ptrs = y_ptr + pid_b * str_y_B + pid_c * str_y_C\n",
    "    dy_ptrs = dy_ptr + pid_b * str_y_B + pid_c * str_y_C\n",
    "\n",
    "    if IS_P_TENSOR:\n",
    "        p = tl.load(p)\n",
    "\n",
    "    # calculate y-level grad\n",
    "    y = tl.load(y_ptrs)\n",
    "    dy = tl.load(dy_ptrs)\n",
    "\n",
    "    if IS_P_TENSOR:\n",
    "        dp = -tl.log(y) / p * y * dy\n",
    "    dy = dy / p * y / (tu.pow(y, p) * L * M * N)\n",
    "\n",
    "    # re-calculate x for x-level grad\n",
    "    for idx_l in range(tl.cdiv(L, BLK_L)):\n",
    "        mask_l = offs_l[:, None, None] < L - idx_l * BLK_L\n",
    "        for idx_m in range(tl.cdiv(M, BLK_M)):\n",
    "            mask_m = offs_m[None, :, None] < M - idx_m * BLK_M\n",
    "            for idx_n in range(tl.cdiv(N, BLK_N)):\n",
    "                mask = mask_l & mask_m & (offs_n[None, None, :] < N - idx_n * BLK_N)\n",
    "                x = tl.load(x_ptrs, mask=mask, other=0.0)  # l\n",
    "\n",
    "                # calculate adaptive average pooling\n",
    "                x_ = tl.where(mask & (x < eps), eps, x)\n",
    "                x_p1 = tu.pow(x_, p - 1)\n",
    "                dx = tl.zeros((BLK_L, BLK_M, BLK_N), dtype=x.dtype) + dy  # l m\n",
    "\n",
    "                if IS_P_TENSOR:\n",
    "                    dp_tmp = tl.where(mask, x_p1 * x_ * tl.log(x_) * dx, 0.0)\n",
    "                    dp += tl.sum(dp_tmp)\n",
    "\n",
    "                dx *= p * x_p1\n",
    "                dx = tl.where((x < eps) & mask, 0.0, dx)\n",
    "\n",
    "                tl.store(dx_ptrs, dx, mask=mask)\n",
    "                x_ptrs += BLK_N * str_x_N\n",
    "                dx_ptr += BLK_N * str_x_N\n",
    "            x_ptrs += BLK_M * str_x_M\n",
    "            dx_ptrs += BLK_M * str_x_M\n",
    "        x_ptrs += BLK_L * str_x_L\n",
    "        dx_ptrs += BLK_L * str_x_L\n",
    "\n",
    "    if IS_P_TENSOR:\n",
    "        tl.atomic_add(dp_ptr, dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10541f3f-32ac-4381-b514-d1378761bb29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GeMOps3d(th.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x: Tensor, p: Union[float, Tensor] = 3.0, eps: float = 1e-6, keepdim=True):\n",
    "        ctx.is_p_tensor = isinstance(p, Tensor)\n",
    "        assert x.ndim == 5, f\"Unknown shape of `x`: {x.shape}\"\n",
    "\n",
    "        B, C, L, M, N = x.shape\n",
    "        y = x.new_empty(list(x.shape[:2]) + ([1, 1, 1] if keepdim else []))  # b c\n",
    "        # str_x_B, str_x_C, str_x_L, str_x_M, str_x_N = x.stride()\n",
    "        # str_y_B, str_y_C = y.stride(0), y.stride(1)\n",
    "        strides = (*x.stride(), *y.stride()[:2])\n",
    "\n",
    "        grid = lambda meta: (B, C)\n",
    "        gem_forward_3d_kernel[grid](x, y, p, eps, *strides, L, M, N, IS_P_TENSOR=ctx.is_p_tensor)\n",
    "\n",
    "        if ctx.is_p_tensor:\n",
    "            ctx.save_for_backward(x, p, y)\n",
    "            ctx.params = (eps,)\n",
    "        else:\n",
    "            ctx.save_for_backward(x, y)\n",
    "            ctx.params = p, eps\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dy: Tensor):\n",
    "        if ctx.is_p_tensor:\n",
    "            x, p, y = ctx.saved_tensors\n",
    "            (eps,) = ctx.params\n",
    "        else:\n",
    "            x, y = ctx.saved_tensors\n",
    "            p, eps = ctx.params\n",
    "\n",
    "        B, C, L, M, N = x.shape\n",
    "        # str_x_B, str_x_C, str_x_L, str_x_M, str_x_N = x.stride()\n",
    "        # str_y_B, str_y_C = y.stride()\n",
    "        strides = (*x.stride(), *y.stride()[:2])\n",
    "\n",
    "        dx = th.empty_like(x)\n",
    "        dp = None\n",
    "        if ctx.is_p_tensor:\n",
    "            dp = th.zeros_like(p)\n",
    "\n",
    "        grid = lambda meta: (B, C)\n",
    "        gem_backward_3d_kernel[grid](x, y, p, dx, dy, dp, eps, *strides, L, M, N, IS_P_TENSOR=ctx.is_p_tensor)\n",
    "        return dx, dp, None, None, None\n",
    "\n",
    "\n",
    "def gem_ops3d(x: Tensor, p: Union[float, Tensor] = 3.0, eps: float = 1e-6, keepdim=True):\n",
    "    return GeMOps3d.apply(x, p, eps, keepdim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66416993-97e4-44eb-979d-035718ac4cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, C, L, M, N = 5, 6, 7, 8, 9\n",
    "x = th.rand(B, C, L, M, N, device=\"cuda\", requires_grad=True)\n",
    "x = x.permute(0, 2, 1, 3, 4)\n",
    "x.retain_grad()\n",
    "p = th.full((1,), 2.0, device=\"cuda\", requires_grad=True)\n",
    "# y_gt = th.randn(B, C, device=\"cuda\")\n",
    "y_gt = th.randn(B, L, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e32d50f-474a-4f89-a2df-b1d610692fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tri = gem_ops3d(x, p, keepdim=False)\n",
    "y_tri.backward(y_gt, retain_graph=True)\n",
    "x_grad_tri, x.grad = x.grad, None\n",
    "p_grad_tri, p.grad = p.grad, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be94100-7b8f-4b7f-a5d4-2370f12d4a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pth = gem_torch_2d(x, p, keepdim=False)\n",
    "y_pth.backward(y_gt, retain_graph=True)\n",
    "x_grad_pth, x.grad = x.grad, None\n",
    "p_grad_pth, p.grad = p.grad, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ff613e-286c-4fa2-9ded-a4026712d523",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.allclose(y_pth, y_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3519ac-ec5f-4a4a-803e-16cd7b067561",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.allclose(x_grad_pth, x_grad_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b68e051-090b-423b-b833-9df486800fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.allclose(p_grad_pth, p_grad_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3529ae86-f078-4096-a085-1ded79548b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_grad_pth - p_grad_tri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3336ef-7f07-4a74-91ff-70c3c115055d",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71e6e8d-932d-467b-9ea3-6c24bc08d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.testing.perf_report(\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=[\"L\", \"M\"],\n",
    "        x_vals=[16 * 2**i for i in range(1, 8)],\n",
    "        x_log=False,\n",
    "        line_arg=\"provider\",\n",
    "        line_vals=[\"triton\", \"torch\", \"torch_old\"],\n",
    "        line_names=[\"Triton\", \"Torch\", \"Torch_old\"],\n",
    "        styles=[(\"blue\", \"-\"), (\"green\", \"-\"), (\"red\", \"-\")],\n",
    "        ylabel=\"GB/s\",\n",
    "        plot_name=\"a\",\n",
    "        args={\"B\": 2, \"C\": 64, \"p\": 2.0},\n",
    "    )\n",
    ")\n",
    "def benchmark(B, C, L, M, p, provider):\n",
    "    x = th.rand(B, C, L, M, device=\"cuda\")\n",
    "\n",
    "    quantiles = [0.5, 0.2, 0.8]\n",
    "    if provider == \"torch\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(\n",
    "            lambda: gem_torch_2d(x, p, keepdim=False),\n",
    "            quantiles=quantiles,\n",
    "        )\n",
    "    elif provider == \"torch_old\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(\n",
    "            lambda: gem_torch_old(x, p),\n",
    "            quantiles=quantiles,\n",
    "        )\n",
    "    elif provider == \"triton\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(\n",
    "            lambda: gem_ops2d(x, p, keepdim=False),\n",
    "            quantiles=quantiles,\n",
    "        )\n",
    "\n",
    "    gbps = lambda ms: (x.nelement() * x.element_size()) * 1e-9 / (ms * 1e-3)\n",
    "    return gbps(ms), gbps(max_ms), gbps(min_ms)\n",
    "\n",
    "\n",
    "benchmark.run(show_plots=True, print_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1a50dd-e3cc-4937-8d90-60f4db93d74d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2581971c-2e84-40a4-b6f7-814301f975b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
